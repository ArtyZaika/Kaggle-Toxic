{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w/anaconda3/envs/idp3exp/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/w/anaconda3/envs/idp3exp/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "import utils_fe\n",
    "from gbm_pipeline import GBMPipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_oof = 'oof/'\n",
    "src_preds = '/home/w/Projects/Toxic/scripts/predictions/'\n",
    "src_features = '../data/features/'\n",
    "\n",
    "run_kfold = True\n",
    "split_for_validation = True\n",
    "add_features = True\n",
    "\n",
    "run_kfold = 1\n",
    "\n",
    "\n",
    "if run_kfold:\n",
    "    prefix = 'KFold'\n",
    "else:\n",
    "    prefix = 'Bag'\n",
    "    \n",
    "run_name = 'LGB_{}_StackerNext_Params1'.format(prefix),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train files:\n",
      "\n",
      "['oof/train/Conv2Dmodel128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Nadam0.001_Stratified_27.31593.pkl',\n",
      " 'oof/train/Conv2Dmodel128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Nadam0.001_Stratified_fromCheck_27.31593.pkl',\n",
      " 'oof/train/GRUCapsuleBidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_22.37225.pkl',\n",
      " 'oof/train/GRUHierarchicalBidirectional128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_23.81552.pkl',\n",
      " 'oof/train/GRUconcat2Bidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_21.74320.pkl',\n",
      " 'oof/train/GRUconcatBidirectional256_1stSet_KFold1_Glove_BasicClean_200dim_300k_256len_random0_5fold_BS512_Nadam_94.57426.pkl',\n",
      " 'oof/train/GRUconcatBidirectional256_1stSet_KFold1_Glove_BasicClean_200dim_300k_256len_random0_5fold_BS512_Nadam_fromCheck_94.57426.pkl',\n",
      " 'oof/train/GRUconvconcat2Bidirectional128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_23.64375.pkl',\n",
      " 'oof/train/GRUdeepBidirectional128_KF1_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_20.93988.pkl',\n",
      " 'oof/train/GRUdeepBidirectional128_KF1_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_fromCheck_20.93988.pkl',\n",
      " 'oof/train/GRUdeepBidirectional128_KF2_KFold1_Glove_BasicClean2_200dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_23.18845.pkl',\n",
      " 'oof/train/GRUmaxBidirectional256_1stSet_KFold1_Glove_BasicClean_200dim_300k_256len_random0_5fold_BS512_Nadam_95.19805.pkl',\n",
      " 'oof/train/LSTMHierarchicalBidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_22.44281.pkl',\n",
      " 'oof/train/LSTMHierarchicalBidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_fromCheck_22.44281.pkl',\n",
      " 'oof/train/LSTMattentionBidirectional256_1stSet_KFold1_Glove_BasicClean_200dim_300k_256len_random0_5fold_BS512_Adam_116.43670.pkl',\n",
      " 'oof/train/LSTMconcat2Bidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_480len_random0_5fold_BS256_Adam0.001_Stratified_22.86836.pkl',\n",
      " 'oof/train/LSTMconcat2Bidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_480len_random0_5fold_BS256_Adam0.001_Stratified_fromCheck_22.86836.pkl',\n",
      " 'oof/train/LSTMdeep2Bidirectional128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Nadam0.001_Stratified_22.02310.pkl',\n",
      " 'oof/train/LSTMdeep2Bidirectional128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Nadam0.001_Stratified_fromCheck_22.02310.pkl',\n",
      " 'oof/train/LSTMdeepBidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_21.75960.pkl',\n",
      " 'oof/train/LSTMdeepBidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_fromCheck_21.75961.pkl',\n",
      " 'oof/train/LSTMdeepBidirectional128_KF2_KFold1_Glove_BasicClean2_200dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_24.22019.pkl']\n",
      "\n",
      "Test files:\n",
      "\n",
      "['oof/test/Conv2Dmodel128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Nadam0.001_Stratified_27.31593.pkl',\n",
      " 'oof/test/Conv2Dmodel128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Nadam0.001_Stratified_fromCheck_27.31593.pkl',\n",
      " 'oof/test/GRUCapsuleBidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_22.37225.pkl',\n",
      " 'oof/test/GRUHierarchicalBidirectional128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_23.81552.pkl',\n",
      " 'oof/test/GRUconcat2Bidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_21.74320.pkl',\n",
      " 'oof/test/GRUconcatBidirectional256_1stSet_KFold1_Glove_BasicClean_200dim_300k_256len_random0_5fold_BS512_Nadam_94.57426.pkl',\n",
      " 'oof/test/GRUconcatBidirectional256_1stSet_KFold1_Glove_BasicClean_200dim_300k_256len_random0_5fold_BS512_Nadam_fromCheck_94.57426.pkl',\n",
      " 'oof/test/GRUconvconcat2Bidirectional128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_23.64375.pkl',\n",
      " 'oof/test/GRUdeepBidirectional128_KF1_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_20.93988.pkl',\n",
      " 'oof/test/GRUdeepBidirectional128_KF1_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_fromCheck_20.93988.pkl',\n",
      " 'oof/test/GRUdeepBidirectional128_KF2_KFold1_Glove_BasicClean2_200dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_23.18845.pkl',\n",
      " 'oof/test/GRUmaxBidirectional256_1stSet_KFold1_Glove_BasicClean_200dim_300k_256len_random0_5fold_BS512_Nadam_95.19805.pkl',\n",
      " 'oof/test/LSTMHierarchicalBidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_22.44281.pkl',\n",
      " 'oof/test/LSTMHierarchicalBidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_fromCheck_22.44281.pkl',\n",
      " 'oof/test/LSTMattentionBidirectional256_1stSet_KFold1_Glove_BasicClean_200dim_300k_256len_random0_5fold_BS512_Adam_116.43670.pkl',\n",
      " 'oof/test/LSTMconcat2Bidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_480len_random0_5fold_BS256_Adam0.001_Stratified_22.86836.pkl',\n",
      " 'oof/test/LSTMconcat2Bidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_480len_random0_5fold_BS256_Adam0.001_Stratified_fromCheck_22.86836.pkl',\n",
      " 'oof/test/LSTMdeep2Bidirectional128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Nadam0.001_Stratified_22.02310.pkl',\n",
      " 'oof/test/LSTMdeep2Bidirectional128_KF3_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Nadam0.001_Stratified_fromCheck_22.02310.pkl',\n",
      " 'oof/test/LSTMdeepBidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_21.75960.pkl',\n",
      " 'oof/test/LSTMdeepBidirectional128_KF2_KFold1_FastText2_BasicClean2_300dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_fromCheck_21.75961.pkl',\n",
      " 'oof/test/LSTMdeepBidirectional128_KF2_KFold1_Glove_BasicClean2_200dim_200k_320len_random0_5fold_BS256_Adam0.001_Stratified_24.22019.pkl']\n",
      "(22, 159571, 6, 1) (22, 153164, 6, 5)\n",
      "(159571, 358) (153164, 358)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_pickle(\"../data/train_basic_clean.pkl\")\n",
    "test = pd.read_pickle(\"../data/test_basic_clean.pkl\")\n",
    "target_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "oof_tr, oof_te = utils.load_predictions(src_oof, contains='')\n",
    "oof_tr, oof_te = np.asarray(oof_tr), np.asarray(oof_te)\n",
    "print(oof_tr.shape, oof_te.shape)\n",
    "\n",
    "X_train_oof = pd.DataFrame()\n",
    "X_test_oof = pd.DataFrame()\n",
    "\n",
    "for i in range(oof_tr.shape[0]):\n",
    "    oof_tr_part = oof_tr[i][:, :, 0]\n",
    "    oof_te_part = oof_te[i].mean(axis=-1)[:, :]\n",
    "    X_train_oof = pd.concat([X_train_oof, pd.DataFrame(oof_tr_part)], axis=1)\n",
    "    X_test_oof = pd.concat([X_test_oof, pd.DataFrame(oof_te_part)], axis=1)\n",
    "\n",
    "\n",
    "f_cols = []\n",
    "\n",
    "for i in range((X_train_oof.shape[1] // 6)):\n",
    "    f_cols.extend(['{}_preds_model{}'.format(target_columns[x], i) for x in range(len(target_columns))])\n",
    "\n",
    "X_train_oof.columns = f_cols\n",
    "X_test_oof.columns = f_cols\n",
    "\n",
    "\n",
    "if add_features:\n",
    "    data_tokenized = pd.read_pickle(src_features + 'data_TokenizedSentences160.pkl')\n",
    "    data_badwords300 = pd.read_pickle(src_features + 'data_Binary300Badwords.pkl')\n",
    "    data_textStatistics = pd.read_pickle(src_features + 'data_TextStatistics.pkl')\n",
    "    data_transformations = pd.read_pickle(src_features + 'data_20dim_SVDLSA.pkl')\n",
    "\n",
    "    data_tokenized.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    X = pd.concat([data_tokenized, data_textStatistics, data_transformations], axis=1)\n",
    "    X['badwordsCount'] = data_badwords300.sum(axis=1)\n",
    "\n",
    "    X_train = X.iloc[:train.shape[0], :]\n",
    "    X_test = X.iloc[train.shape[0]:, :]\n",
    "    y_train = train[target_columns].values\n",
    "    \n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    features = np.setdiff1d(X_train.columns, target_columns)\n",
    "\n",
    "    X_train = pd.concat([X_train[features], X_train_oof], axis=1)\n",
    "    X_test = pd.concat([X_test[features], X_test_oof], axis=1)\n",
    "    \n",
    "    del X, test\n",
    "    del data_tokenized, data_badwords300\n",
    "    del data_textStatistics, data_transformations\n",
    "    gc.collect()\n",
    "\n",
    "else:\n",
    "    X_train = X_train_oof\n",
    "    y_train = train[target_columns].values\n",
    "    X_test = X_test_oof\n",
    "    \n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.output_submission(oof_te.mean(axis=-1).mean(axis=0), 'GRU&LSTM_5models_blend', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logloss',\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 1,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'scale_pos_weight': 1,\n",
    "    'subsample': 0.8,\n",
    "    'lambda': 0,\n",
    "    'tree_method': 'hist',\n",
    "    'nthread': 4,\n",
    "    'silent': True,\n",
    "    'base_score': 0.0,\n",
    "}\n",
    "\n",
    "# Best Recruit's parameters\n",
    "lgb_params1 = {\n",
    "    'learning_rate': 0.05,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'sub_feature': 0.7,\n",
    "    'num_leaves': 60,\n",
    "    'min_data': 100,\n",
    "    'min_hessian': 1,\n",
    "    'verbose': -1,\n",
    "    'num_threads': 10,\n",
    "}\n",
    "\n",
    "# Best Favorita parameters\n",
    "lgb_params2 = {\n",
    "    'learning_rate': 0.05,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'min_data_in_leaf': 200,\n",
    "    'num_leaves': 80,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 1,\n",
    "    'num_threads': 10,\n",
    "}\n",
    "\n",
    "\n",
    "if split_for_validation:\n",
    "    \n",
    "    train_params = {\n",
    "        'boost_round': 10000,\n",
    "        'stopping_rounds': 50,\n",
    "        'verbose_eval': 50,\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    \n",
    "    train_params = {\n",
    "        'boost_round': 161,\n",
    "        'stopping_rounds': 50,\n",
    "        'verbose_eval': False,\n",
    "    }\n",
    "\n",
    "    \n",
    "pipeline_params = {\n",
    "    'use_lgb': True,\n",
    "    'predict_test': True,\n",
    "    'seed': 1337,\n",
    "    'shuffle': True,\n",
    "    'verbose': True,\n",
    "    'run_save_name': run_name,\n",
    "    'save_model': False,\n",
    "    'save_history': False,\n",
    "    'save_statistics': True,\n",
    "    'output_statistics': True,\n",
    "    'output_importance': True,\n",
    "}\n",
    "\n",
    "\n",
    "XGB_pipeline = GBMPipeline(\n",
    "    use_lgb=pipeline_params['use_lgb'],\n",
    "    predict_test=pipeline_params['predict_test'],\n",
    "    seed=pipeline_params['seed'],\n",
    "    shuffle=pipeline_params['shuffle'],\n",
    "    verbose=pipeline_params['verbose'],\n",
    "    run_save_name=pipeline_params['run_save_name'],\n",
    "    save_model=pipeline_params['save_model'],\n",
    "    save_history=pipeline_params['save_history'],\n",
    "    save_statistics=pipeline_params['save_statistics'],\n",
    "    output_statistics=pipeline_params['output_statistics'],\n",
    "    output_importance=pipeline_params['output_importance'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(X_train.columns, X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LightGBM\n",
      "OOF train predictions shape: (159571, 6)\n",
      "X_train shape: (159571, 358)\n",
      "OOF test predictions shape: (153164, 6, 5)\n",
      "X_test shape: (153164, 358)\n",
      "Running KFold run with 5 folds\n",
      "Start training with parameters: {'learning_rate': 0.05, 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'sub_feature': 0.7, 'num_leaves': 60, 'min_data': 100, 'min_hessian': 1, 'verbose': -1, 'num_threads': 10} \n",
      " \n",
      "\n",
      "Training model for column: toxic\n",
      "(127655, 248) (31916, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.985506\n",
      "[100]\tvalid_0's auc: 0.98571\n",
      "[150]\tvalid_0's auc: 0.986067\n",
      "[200]\tvalid_0's auc: 0.985978\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's auc: 0.986073\n",
      "Minimum validation split loss for current fold/bag: 0.9860734831568813 \n",
      "\n",
      "Seconds it took to train the model: 41.078657388687134 \n",
      "\n",
      "Best iterations: [153, 24, 153] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: severe_toxic\n",
      "(127655, 248) (31916, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.988037\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.989456\n",
      "Minimum validation split loss for current fold/bag: 0.9894556855842824 \n",
      "\n",
      "Seconds it took to train the model: 46.90303611755371 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: obscene\n",
      "(127655, 248) (31916, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.993715\n",
      "[100]\tvalid_0's auc: 0.994368\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.994526\n",
      "Minimum validation split loss for current fold/bag: 0.9945256786965665 \n",
      "\n",
      "Seconds it took to train the model: 53.5078022480011 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: threat\n",
      "(127655, 248) (31916, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.997127\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.99743\n",
      "Minimum validation split loss for current fold/bag: 0.997430123518856 \n",
      "\n",
      "Seconds it took to train the model: 58.267603635787964 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: insult\n",
      "(127655, 248) (31916, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.988877\n",
      "[100]\tvalid_0's auc: 0.98899\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.989036\n",
      "Minimum validation split loss for current fold/bag: 0.9890360117580206 \n",
      "\n",
      "Seconds it took to train the model: 66.41278529167175 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: identity_hate\n",
      "(127655, 248) (31916, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.988936\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.989239\n",
      "Minimum validation split loss for current fold/bag: 0.9892385885449981 \n",
      "\n",
      "Seconds it took to train the model: 72.12824082374573 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: toxic\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.986482\n",
      "[100]\tvalid_0's auc: 0.986424\n",
      "[150]\tvalid_0's auc: 0.986617\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.986746\n",
      "Minimum validation split loss for current fold/bag: 0.9867460929075409 \n",
      "\n",
      "Seconds it took to train the model: 83.16844701766968 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: severe_toxic\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.989117\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.989337\n",
      "Minimum validation split loss for current fold/bag: 0.9893365062720958 \n",
      "\n",
      "Seconds it took to train the model: 88.07981967926025 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: obscene\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.994584\n",
      "[100]\tvalid_0's auc: 0.99483\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.994858\n",
      "Minimum validation split loss for current fold/bag: 0.9948582572755823 \n",
      "\n",
      "Seconds it took to train the model: 96.00360822677612 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: threat\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.946555\n",
      "[100]\tvalid_0's auc: 0.955231\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.955942\n",
      "Minimum validation split loss for current fold/bag: 0.955942310552389 \n",
      "\n",
      "Seconds it took to train the model: 102.69310927391052 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: insult\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.989433\n",
      "[100]\tvalid_0's auc: 0.989443\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.989467\n",
      "Minimum validation split loss for current fold/bag: 0.989467171429038 \n",
      "\n",
      "Seconds it took to train the model: 110.83319401741028 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: identity_hate\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.98502\n",
      "[100]\tvalid_0's auc: 0.985651\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.985973\n",
      "Minimum validation split loss for current fold/bag: 0.9859727246301918 \n",
      "\n",
      "Seconds it took to train the model: 117.10006070137024 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: toxic\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.985323\n",
      "[100]\tvalid_0's auc: 0.985875\n",
      "[150]\tvalid_0's auc: 0.985904\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.985927\n",
      "Minimum validation split loss for current fold/bag: 0.9859273946327891 \n",
      "\n",
      "Seconds it took to train the model: 126.97395968437195 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: severe_toxic\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.991419\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.99165\n",
      "Minimum validation split loss for current fold/bag: 0.9916499525489381 \n",
      "\n",
      "Seconds it took to train the model: 132.84948897361755 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: obscene\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.992604\n",
      "[100]\tvalid_0's auc: 0.994903\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.994995\n",
      "Minimum validation split loss for current fold/bag: 0.9949953453430038 \n",
      "\n",
      "Seconds it took to train the model: 141.1767394542694 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: threat\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's auc: 0.976045\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.976511\n",
      "Minimum validation split loss for current fold/bag: 0.976510842405677 \n",
      "\n",
      "Seconds it took to train the model: 147.4505820274353 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: insult\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.988242\n",
      "[100]\tvalid_0's auc: 0.989028\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.989045\n",
      "Minimum validation split loss for current fold/bag: 0.9890447787754671 \n",
      "\n",
      "Seconds it took to train the model: 157.00836563110352 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: identity_hate\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.978626\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.979941\n",
      "Minimum validation split loss for current fold/bag: 0.9799412703950209 \n",
      "\n",
      "Seconds it took to train the model: 162.42673206329346 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: toxic\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.984289\n",
      "[100]\tvalid_0's auc: 0.984852\n",
      "[150]\tvalid_0's auc: 0.984641\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's auc: 0.98489\n",
      "Minimum validation split loss for current fold/bag: 0.9848895913747252 \n",
      "\n",
      "Seconds it took to train the model: 174.3761692047119 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: severe_toxic\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.991963\n",
      "[100]\tvalid_0's auc: 0.99177\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.991963\n",
      "Minimum validation split loss for current fold/bag: 0.9919631189604213 \n",
      "\n",
      "Seconds it took to train the model: 181.4167459011078 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: obscene\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.992774\n",
      "[100]\tvalid_0's auc: 0.993821\n",
      "[150]\tvalid_0's auc: 0.993705\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.993847\n",
      "Minimum validation split loss for current fold/bag: 0.9938473886798779 \n",
      "\n",
      "Seconds it took to train the model: 192.38267135620117 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50, 101] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: threat\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.9859\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.990853\n",
      "Minimum validation split loss for current fold/bag: 0.9908530682213308 \n",
      "\n",
      "Seconds it took to train the model: 197.36053013801575 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50, 101, 5] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: insult\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.986377\n",
      "[100]\tvalid_0's auc: 0.986754\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.986911\n",
      "Minimum validation split loss for current fold/bag: 0.9869112590957162 \n",
      "\n",
      "Seconds it took to train the model: 204.49409341812134 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50, 101, 5, 72] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: identity_hate\n",
      "(127657, 248) (31914, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.99294\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.993052\n",
      "Minimum validation split loss for current fold/bag: 0.993051881822898 \n",
      "\n",
      "Seconds it took to train the model: 210.16393208503723 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50, 101, 5, 72, 42] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: toxic\n",
      "(127658, 248) (31913, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.985957\n",
      "[100]\tvalid_0's auc: 0.986364\n",
      "[150]\tvalid_0's auc: 0.986452\n",
      "[200]\tvalid_0's auc: 0.986393\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's auc: 0.98647\n",
      "Minimum validation split loss for current fold/bag: 0.9864704498970835 \n",
      "\n",
      "Seconds it took to train the model: 225.02357625961304 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50, 101, 5, 72, 42, 160] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: severe_toxic\n",
      "(127658, 248) (31913, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.989129\n",
      "[100]\tvalid_0's auc: 0.990175\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.990517\n",
      "Minimum validation split loss for current fold/bag: 0.9905167087795724 \n",
      "\n",
      "Seconds it took to train the model: 231.977792263031 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50, 101, 5, 72, 42, 160, 68] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: obscene\n",
      "(127658, 248) (31913, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.993244\n",
      "[100]\tvalid_0's auc: 0.99397\n",
      "[150]\tvalid_0's auc: 0.994346\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's auc: 0.994362\n",
      "Minimum validation split loss for current fold/bag: 0.9943620191922553 \n",
      "\n",
      "Seconds it took to train the model: 241.7255139350891 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50, 101, 5, 72, 42, 160, 68, 138] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: threat\n",
      "(127658, 248) (31913, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.994967\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.99506\n",
      "Minimum validation split loss for current fold/bag: 0.9950600619973468 \n",
      "\n",
      "Seconds it took to train the model: 248.94788908958435 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50, 101, 5, 72, 42, 160, 68, 138, 48] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: insult\n",
      "(127658, 248) (31913, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.987836\n",
      "[100]\tvalid_0's auc: 0.988725\n",
      "[150]\tvalid_0's auc: 0.988434\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.988744\n",
      "Minimum validation split loss for current fold/bag: 0.9887443134739029 \n",
      "\n",
      "Seconds it took to train the model: 258.8135087490082 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50, 101, 5, 72, 42, 160, 68, 138, 48, 113] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: identity_hate\n",
      "(127658, 248) (31913, 248) (153164, 248)\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.98781\n",
      "[100]\tvalid_0's auc: 0.98795\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.988146\n",
      "Minimum validation split loss for current fold/bag: 0.9881459991555999 \n",
      "\n",
      "Seconds it took to train the model: 265.8731904029846 \n",
      "\n",
      "Best iterations: [153, 24, 153, 24, 82, 16, 89, 39, 119, 19, 92, 53, 89, 80, 111, 29, 91, 28, 90, 22, 103, 50, 101, 5, 72, 42, 160, 68, 138, 48, 113, 79] \n",
      "\n",
      "Visualize model feature importance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test data.\n",
      "Mean loss for current KFold run: 0.9883280389943511\n",
      "Preparing submission.\n"
     ]
    }
   ],
   "source": [
    "if pipeline_params['use_lgb']:\n",
    "    gbm_params = lgb_params1\n",
    "else:\n",
    "    gbm_params = xgb_params\n",
    "    \n",
    "if not add_features:\n",
    "    features = None\n",
    "\n",
    "\n",
    "if pipeline_params['predict_test']:\n",
    "    val_preds, test_preds, gbm = XGB_pipeline.fold_run(X_train, train[target_columns],\n",
    "                                           X_test=X_test,\n",
    "                                           model_params=gbm_params,\n",
    "                                           train_params=train_params,\n",
    "                                           output_submission=True,\n",
    "                                           additional_features=features,\n",
    "                                           save_oof=True,\n",
    "                                           stratify=True)\n",
    "else:\n",
    "    val_preds, gbm = XGB_pipeline.fold_run(X_train[features], y_train=X_train[targets],\n",
    "                               model_params=gbm_params,\n",
    "                               train_params=train_params)\n",
    "\n",
    "\n",
    "utils.save_parameter_dict(\n",
    "    'checkpoints/{0}/{0}_gbm_parameters.txt'.format(pipeline_params['run_save_name']), gbm_params)\n",
    "utils.save_parameter_dict('checkpoints/{0}/{0}_train_parameters.txt'.format(\n",
    "    pipeline_params['run_save_name']), train_params)\n",
    "utils.save_parameter_dict('checkpoints/{0}/{0}_pipeline_parameters.txt'.format(\n",
    "    pipeline_params['run_save_name']), pipeline_params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "oof_test_mean = test_preds.mean(axis=0)\n",
    "\n",
    "submission = utils.output_submission(\n",
    "    oof_test_mean, run_name, save=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if pipeline_params['use_lgb']:\n",
    "    gbm_params = lgb_params\n",
    "else:\n",
    "    gbm_params = xgb_params\n",
    "\n",
    "\n",
    "if pipeline_params['predict_test']:\n",
    "    val_preds, test_preds, gbm = XGB_pipeline.bag_run(X_train[features], y_train=train[target_columns],\n",
    "                                           #X_valid=X_valid[features], y_valid=X_valid[target_columns],\n",
    "                                           X_test=X_test[features],\n",
    "                                           model_params=gbm_params,\n",
    "                                           train_params=train_params,\n",
    "                                           output_submission=True)\n",
    "else:\n",
    "    val_preds, gbm = XGB_pipeline.bag_run(X_train[features], y_train=X_train[targets],\n",
    "                               model_params=gbm_params,\n",
    "                               train_params=train_params)\n",
    "\n",
    "\n",
    "utils.save_parameter_dict(\n",
    "    'checkpoints/{0}/{0}_gbm_parameters.txt'.format(pipeline_params['run_save_name']), gbm_params)\n",
    "utils.save_parameter_dict('checkpoints/{0}/{0}_train_parameters.txt'.format(\n",
    "    pipeline_params['run_save_name']), train_params)\n",
    "utils.save_parameter_dict('checkpoints/{0}/{0}_pipeline_parameters.txt'.format(\n",
    "    pipeline_params['run_save_name']), pipeline_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
