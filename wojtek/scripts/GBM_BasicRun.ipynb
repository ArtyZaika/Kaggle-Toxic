{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "import utils_fe\n",
    "from gbm_pipeline import GBMPipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_features = '/home/w/Projects/Toxic/data/features/'\n",
    "run_kfold = True\n",
    "split_for_validation = True\n",
    "\n",
    "if run_kfold:\n",
    "    prefix = 'KFold'\n",
    "else:\n",
    "    prefix = 'Bag'\n",
    "\n",
    "\n",
    "train = pd.read_pickle(\"../data/train_basic_clean.pkl\")\n",
    "test = pd.read_pickle(\"../data/test_basic_clean.pkl\")\n",
    "target_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "\n",
    "data_tokenized = pd.read_pickle(src_features + 'data_TokenizedSentences196.pkl')\n",
    "data_badwords300 = pd.read_pickle(src_features + 'data_Binary300Badwords.pkl')\n",
    "data_badwordsCount = pd.read_pickle(src_features + 'data_BadwordsCount.pkl')\n",
    "data_textStatistics = pd.read_pickle(src_features + 'data_TextStatistics.pkl')\n",
    "data_transformations = pd.read_pickle(src_features + 'data_TransformationsFeats20dim_SVDLSA.pkl')\n",
    "\n",
    "X = pd.concat([data_tokenized, data_badwords300, data_textStatistics, data_transformations], axis=1)\n",
    "X['badwordsCount'] = data_badwordsCount\n",
    "\n",
    "X_train = X.iloc[:train.shape[0], :]\n",
    "X_test = X.iloc[train.shape[0]:, :]\n",
    "\n",
    "features = np.setdiff1d(X_train.columns, target_columns)\n",
    "\n",
    "\n",
    "del X, test\n",
    "del data_tokenized, data_badwords300, data_badwordsCount\n",
    "del data_textStatistics, data_transformations\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.iloc[:train.shape[0], :][:1000]\n",
    "train = train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 10,\n",
    "    'min_child_weight': 20,\n",
    "    'subsample': 0.8,\n",
    "    'lambda': 0,\n",
    "    'tree_method': 'hist',\n",
    "    'nthread': 10,\n",
    "    'silent': True,\n",
    "}\n",
    "\n",
    "lgb_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 255,\n",
    "    'max_depth': 10,\n",
    "    'min_child_weight': 20,\n",
    "    'subsample': 0.8,\n",
    "    'reg_lambda': 0,\n",
    "    'nthread': 10,\n",
    "}\n",
    "\n",
    "\n",
    "if split_for_validation:\n",
    "    \n",
    "    train_params = {\n",
    "        'boost_round': 10000,\n",
    "        'stopping_rounds': 50,\n",
    "        'verbose_eval': False,\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    \n",
    "    train_params = {\n",
    "        'boost_round': 161,\n",
    "        'stopping_rounds': 50,\n",
    "        'verbose_eval': False,\n",
    "    }\n",
    "\n",
    "    \n",
    "pipeline_params = {\n",
    "    'use_lgb': True,\n",
    "    'predict_test': True,\n",
    "    'seed': 1337,\n",
    "    'shuffle': True,\n",
    "    'verbose': True,\n",
    "    'run_save_name': 'LGB_{}_Stats&Transforms'.format(prefix),\n",
    "    'save_model': False,\n",
    "    'save_history': False,\n",
    "    'save_statistics': False,\n",
    "    'output_statistics': True,\n",
    "    'output_importance': True,\n",
    "}\n",
    "\n",
    "\n",
    "XGB_pipeline = GBMPipeline(\n",
    "    use_lgb=pipeline_params['use_lgb'],\n",
    "    predict_test=pipeline_params['predict_test'],\n",
    "    seed=pipeline_params['seed'],\n",
    "    shuffle=pipeline_params['shuffle'],\n",
    "    verbose=pipeline_params['verbose'],\n",
    "    run_save_name=pipeline_params['run_save_name'],\n",
    "    save_model=pipeline_params['save_model'],\n",
    "    save_history=pipeline_params['save_history'],\n",
    "    save_statistics=pipeline_params['save_statistics'],\n",
    "    output_statistics=pipeline_params['output_statistics'],\n",
    "    output_importance=pipeline_params['output_importance'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if pipeline_params['use_lgb']:\n",
    "    gbm_params = lgb_params\n",
    "else:\n",
    "    gbm_params = xgb_params\n",
    "\n",
    "\n",
    "if pipeline_params['predict_test']:\n",
    "    val_preds, test_preds, gbm = XGB_pipeline.bag_run(X_train[features], y_train=train[target_columns],\n",
    "                                           #X_valid=X_valid[features], y_valid=X_valid[target_columns],\n",
    "                                           X_test=X_test[features],\n",
    "                                           model_params=gbm_params,\n",
    "                                           train_params=train_params,\n",
    "                                           output_submission=True)\n",
    "else:\n",
    "    val_preds, gbm = XGB_pipeline.bag_run(X_train[features], y_train=X_train[targets],\n",
    "                               model_params=gbm_params,\n",
    "                               train_params=train_params)\n",
    "\n",
    "\n",
    "utils.save_parameter_dict(\n",
    "    'checkpoints/{0}/{0}_gbm_parameters.txt'.format(pipeline_params['run_save_name']), gbm_params)\n",
    "utils.save_parameter_dict('checkpoints/{0}/{0}_train_parameters.txt'.format(\n",
    "    pipeline_params['run_save_name']), train_params)\n",
    "utils.save_parameter_dict('checkpoints/{0}/{0}_pipeline_parameters.txt'.format(\n",
    "    pipeline_params['run_save_name']), pipeline_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LightGBM\n",
      "OOF train predictions shape: (95851, 6)\n",
      "X_train shape: (95851, 589)\n",
      "OOF test predictions shape: (226998, 6, 5)\n",
      "X_test shape: (226998, 589)\n",
      "Running KFold run with 5 folds\n",
      "Start training with parameters: {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'learning_rate': 0.05, 'num_leaves': 255, 'max_depth': 10, 'min_child_weight': 20, 'subsample': 0.8, 'reg_lambda': 0, 'nthread': 10} \n",
      " \n",
      "\n",
      "Training model for column: toxic\n",
      "Minimum validation split loss for current fold/bag: 0.1462012888106474 \n",
      "\n",
      "Seconds it took to train the model: 22.12356400489807 \n",
      "\n",
      "Best iterations: [453] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: severe_toxic\n",
      "Minimum validation split loss for current fold/bag: 0.024794101812459085 \n",
      "\n",
      "Seconds it took to train the model: 31.673904180526733 \n",
      "\n",
      "Best iterations: [453, 173] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: obscene\n",
      "Minimum validation split loss for current fold/bag: 0.06211385077918359 \n",
      "\n",
      "Seconds it took to train the model: 44.12086868286133 \n",
      "\n",
      "Best iterations: [453, 173, 272] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: threat\n",
      "Minimum validation split loss for current fold/bag: 0.013765641955165896 \n",
      "\n",
      "Seconds it took to train the model: 54.970176219940186 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: insult\n",
      "Minimum validation split loss for current fold/bag: 0.08854552772140341 \n",
      "\n",
      "Seconds it took to train the model: 69.37184071540833 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: identity_hate\n",
      "Minimum validation split loss for current fold/bag: 0.0268841615746841 \n",
      "\n",
      "Seconds it took to train the model: 81.478768825531 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: toxic\n",
      "Minimum validation split loss for current fold/bag: 0.14353898837101758 \n",
      "\n",
      "Seconds it took to train the model: 100.72683763504028 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: severe_toxic\n",
      "Minimum validation split loss for current fold/bag: 0.024958663812123687 \n",
      "\n",
      "Seconds it took to train the model: 111.03409385681152 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: obscene\n",
      "Minimum validation split loss for current fold/bag: 0.0626605952885283 \n",
      "\n",
      "Seconds it took to train the model: 124.25595998764038 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: threat\n",
      "Minimum validation split loss for current fold/bag: 0.014269300524785332 \n",
      "\n",
      "Seconds it took to train the model: 137.60932302474976 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: insult\n",
      "Minimum validation split loss for current fold/bag: 0.08719555161495078 \n",
      "\n",
      "Seconds it took to train the model: 152.84520292282104 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: identity_hate\n",
      "Minimum validation split loss for current fold/bag: 0.025553753909323244 \n",
      "\n",
      "Seconds it took to train the model: 162.95683884620667 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: toxic\n",
      "Minimum validation split loss for current fold/bag: 0.14711192910302043 \n",
      "\n",
      "Seconds it took to train the model: 181.2478482723236 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: severe_toxic\n",
      "Minimum validation split loss for current fold/bag: 0.026958579755900103 \n",
      "\n",
      "Seconds it took to train the model: 191.21079349517822 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: obscene\n",
      "Minimum validation split loss for current fold/bag: 0.06294589364453917 \n",
      "\n",
      "Seconds it took to train the model: 203.85155034065247 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: threat\n",
      "Minimum validation split loss for current fold/bag: 0.013710363472505665 \n",
      "\n",
      "Seconds it took to train the model: 213.9548008441925 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: insult\n",
      "Minimum validation split loss for current fold/bag: 0.09846714004243264 \n",
      "\n",
      "Seconds it took to train the model: 227.78019976615906 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: identity_hate\n",
      "Minimum validation split loss for current fold/bag: 0.02924477742318255 \n",
      "\n",
      "Seconds it took to train the model: 237.8270332813263 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: toxic\n",
      "Minimum validation split loss for current fold/bag: 0.14458608584056531 \n",
      "\n",
      "Seconds it took to train the model: 257.7490701675415 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: severe_toxic\n",
      "Minimum validation split loss for current fold/bag: 0.027334997304475687 \n",
      "\n",
      "Seconds it took to train the model: 267.7648434638977 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: obscene\n",
      "Minimum validation split loss for current fold/bag: 0.05678270916075259 \n",
      "\n",
      "Seconds it took to train the model: 283.61700797080994 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214, 370] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: threat\n",
      "Minimum validation split loss for current fold/bag: 0.013243281971888602 \n",
      "\n",
      "Seconds it took to train the model: 293.34923553466797 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214, 370, 205] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: insult\n",
      "Minimum validation split loss for current fold/bag: 0.09040455171639432 \n",
      "\n",
      "Seconds it took to train the model: 309.8372256755829 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214, 370, 205, 345] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: identity_hate\n",
      "Minimum validation split loss for current fold/bag: 0.026521566274822505 \n",
      "\n",
      "Seconds it took to train the model: 322.4944415092468 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214, 370, 205, 345, 252] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: toxic\n",
      "Minimum validation split loss for current fold/bag: 0.14711943119864532 \n",
      "\n",
      "Seconds it took to train the model: 349.003511428833 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214, 370, 205, 345, 252, 562] \n",
      "\n",
      "Visualize model feature importance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test data.\n",
      "Training model for column: severe_toxic\n",
      "Minimum validation split loss for current fold/bag: 0.025027475998357838 \n",
      "\n",
      "Seconds it took to train the model: 361.18121314048767 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214, 370, 205, 345, 252, 562, 224] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: obscene\n",
      "Minimum validation split loss for current fold/bag: 0.06486630813522588 \n",
      "\n",
      "Seconds it took to train the model: 376.1468462944031 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214, 370, 205, 345, 252, 562, 224, 245] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: threat\n",
      "Minimum validation split loss for current fold/bag: 0.012478882900373788 \n",
      "\n",
      "Seconds it took to train the model: 388.1970884799957 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214, 370, 205, 345, 252, 562, 224, 245, 275] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: insult\n",
      "Minimum validation split loss for current fold/bag: 0.08403349072593715 \n",
      "\n",
      "Seconds it took to train the model: 402.3117256164551 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214, 370, 205, 345, 252, 562, 224, 245, 275, 413] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Training model for column: identity_hate\n",
      "Minimum validation split loss for current fold/bag: 0.027144079812094574 \n",
      "\n",
      "Seconds it took to train the model: 410.6705479621887 \n",
      "\n",
      "Best iterations: [453, 173, 272, 315, 319, 232, 492, 256, 299, 378, 360, 210, 459, 215, 314, 301, 259, 200, 353, 214, 370, 205, 345, 252, 562, 224, 245, 275, 413, 180] \n",
      "\n",
      "Visualize model feature importance.\n",
      "Predicting on test data.\n",
      "Mean loss for current KFold run: 0.0606154323552\n",
      "Preparing submission.\n"
     ]
    }
   ],
   "source": [
    "if pipeline_params['use_lgb']:\n",
    "    gbm_params = lgb_params\n",
    "else:\n",
    "    gbm_params = xgb_params\n",
    "\n",
    "\n",
    "if pipeline_params['predict_test']:\n",
    "    val_preds, test_preds, gbm = XGB_pipeline.fold_run(X_train[features], y_train=train[target_columns],\n",
    "                                           X_test=X_test[features],\n",
    "                                           model_params=gbm_params,\n",
    "                                           train_params=train_params,\n",
    "                                           output_submission=True)\n",
    "else:\n",
    "    val_preds, gbm = XGB_pipeline.fold_run(X_train[features], y_train=X_train[targets],\n",
    "                               model_params=gbm_params,\n",
    "                               train_params=train_params)\n",
    "\n",
    "\n",
    "utils.save_parameter_dict(\n",
    "    'checkpoints/{0}/{0}_gbm_parameters.txt'.format(pipeline_params['run_save_name']), gbm_params)\n",
    "utils.save_parameter_dict('checkpoints/{0}/{0}_train_parameters.txt'.format(\n",
    "    pipeline_params['run_save_name']), train_params)\n",
    "utils.save_parameter_dict('checkpoints/{0}/{0}_pipeline_parameters.txt'.format(\n",
    "    pipeline_params['run_save_name']), pipeline_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
